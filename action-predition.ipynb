# Step 1: Import necessary libraries
# Import pandas as pd
# Import numpy as np
# Import sklearn.model_selection (for train-test split)
# Import sklearn.tree (for DecisionTreeClassifier)
# Import sklearn.metrics (for evaluation metrics like accuracy, precision, recall)

import polars as pl
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Step 2: Load and preprocess the data
# Load dataset with customer information, recent purchases, and engagement history
# Filter data to focus on active customers, if applicable
# Handle missing values in relevant columns (e.g., recent purchase activity, engagement level)


## edit based on your folder and file location
## edit based on your folder and file location
df = pd.read_csv('/content/Electronic_sales_Sep2023-Sep2024.csv')

df.columns

# Step 3: Feature Engineering
# - Create new features that may affect engagement actions, such as:
#    - Purchase frequency
#    - Recency of last purchase
#    - Average transaction amount
#    - Engagement score (e.g., calculated from loyalty points, reviews, or feedback)
#    - Total lifetime spend, and so on
# Create features from customer demographics, purchase behavior, and engagement scores
df['Purchase Date'] = pd.to_datetime(df['Purchase Date'])
df['purchase_frequency'] = df.groupby('Customer ID')['Purchase Date'].transform('count')
df['recency'] = (pd.to_datetime('today') - df['Purchase Date']).dt.days
df['average_transaction'] = df.groupby('Customer ID')['Total Price'].transform('mean')
df['total_quantity'] = df.groupby('Customer ID')['Quantity'].transform('sum')
weight1, weight2, weight3 = 0.5, -0.3, 0.2
df['engagement_score'] = (
    (df['purchase_frequency'] * weight1) +
    (df['recency'] * weight2) +
    (df['average_transaction'] * weight3) +
    (df['total_quantity'] * 0.1)
 # Additional factor for quantity
)
df['age_group'] = pd.cut(df['Age'], bins=[0, 18, 25, 35, 45, 55, 65, 100],
                         labels=['0-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+'])
df['gender_encoded'] = df['Gender'].map({'Male': 1, 'Female': 0})
df['day_of_week'] = df['Purchase Date'].dt.day_name()
df['month'] = df['Purchase Date'].dt.month

# Step 4: Define Target Variables
# Define target variable for Discount Offers
#Recommend a discount if the customer has made more than 5 purchases and has a low engagement score
df['discount_offer'] = ((df['purchase_frequency'] > 5) & (df['engagement_score'] < 50)).astype(int)

# Define target variable for Loyalty Rewards
# Recommend loyalty rewards if the customer is a loyalty member and has an average transaction amount above $100
df['loyalty_reward'] = ((df['Loyalty Member'] == 'Yes') & (df['average_transaction'] > 100)).astype(int)

#Define target variable for Product Promotions
#Recommend a product promotion if the customer has rated more than 3 on average and purchased a specific product type
df['product_promotion'] = ((df['Rating'] > 3) & (df['Product Type'] == 'Smartphone')).astype(int)

# Display the updated DataFrame with new target variables
print(df[['Customer ID', 'discount_offer', 'loyalty_reward', 'product_promotion']].head())

# Putting feature variable to X
X = df.drop(columns=['Customer ID', 'Purchase Date', 'discount_offer', 'loyalty_reward', 'product_promotion'])

# Putting response variable to y
y = df[['discount_offer', 'loyalty_reward', 'product_promotion']]

# Step 5: Data Preprocessing - Encode Categorical Features
# Create a LabelEncoder object
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()

X['age_group'] = encoder.fit_transform(X['age_group'])

# Iterate through columns and encode categorical features
for column in X.select_dtypes(include=['object']).columns:
    X[column] = encoder.fit_transform(X[column])

for column in y.select_dtypes(include=['object']).columns:
    y[column] = encoder.fit_transform(y[column])

X = pd.get_dummies(X, columns=['age_group'], drop_first=True)

from sklearn.model_selection import train_test_split

# Step 5: Split data into training and testing sets
# Split the data into training and testing sets (e.g., 80-20 split)

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=12345)
X_train.shape, X_test.shape

from sklearn.ensemble import RandomForestClassifier

# Step 6: Initialize the model with recommended parameters
model = RandomForestClassifier(
    n_estimators=150,        # Number of trees
    max_depth=10,            # Maximum depth of each tree
    min_samples_split=10,    # Minimum samples to split an internal node
    min_samples_leaf=5,      # Minimum samples at a leaf node
    random_state=12345       # Seed for reproducibility
)

# Fit the model to the training data
model.fit(X_train, y_train)

# Step 7: Train models for each action
# For each action (e.g., discount_offer, loyalty_reward, product_promotion):
#     - Train the classifier on the training data with the current action as the target
#     - Save the trained model for each action type
from sklearn.metrics import accuracy_score

models = {}
accuracies = {}

for action in y_train.columns:
    print(f"Training model for {action}...")


    # Train the model using X_train and the specific y_train[action]
    model.fit(X_train, y_train[action])

    # Save the trained model in the dictionary
    models[action] = model

    # Make predictions on the test set for the current action
    y_pred = model.predict(X_test)

    # Calculate accuracy for the current action and store it
    accuracy = accuracy_score(y_test[action], y_pred)
    accuracies[action] = accuracy
    print(f"Accuracy for {action}: {accuracy:.2f}\n")

# Optionally, print all accuracies for easy comparison
print("All model accuracies:", accuracies)

# Step 8: Evaluate models
# For each action:
#     - Predict using the trained model on the testing set
#     - Evaluate using accuracy, precision, recall, or F1-score to assess performance
#     - Print or store evaluation metrics for each action model

from sklearn.metrics import classification_report

evaluation_metrics = {}


for action in y_train.columns:
    print(f"Evaluating model for {action}...")

    # Make predictions on the test set for the current action
    y_pred = models[action].predict(X_test)

    # Get the classification report for the current action
    report = classification_report(y_test[action], y_pred, output_dict=True)

    # Store the evaluation metrics in the dictionary
    evaluation_metrics[action] = report

    # Print the evaluation metrics for better readability
    print(f"Classification report for {action}:\n", report)
    print("\n")

# Optional: If you want to summarize key metrics
for action in evaluation_metrics:
    print(f"Summary metrics for {action}:")
    print(f"  Accuracy: {evaluation_metrics[action]['accuracy']:.2f}")
    print(f"  Precision (1): {evaluation_metrics[action]['1']['precision']:.2f}")
    print(f"  Recall (1): {evaluation_metrics[action]['1']['recall']:.2f}")
    print(f"  F1-score (1): {evaluation_metrics[action]['1']['f1-score']:.2f}")
    print("\n")


# Step 9: Make predictions for next best action on new or high-risk customers
# For each customer in the high-risk churn list:
#     - Use the trained models to predict the likelihood of each action (e.g., discount_offer, loyalty_reward)
#     - Choose the action with the highest predicted likelihood (1 = Recommend, 0 = Do not recommend)

import pandas as pd

threshold_total_price = 1139.68  # Example threshold value
high_risk_customers = df[df['Total Price'] < threshold_total_price]

# Check if there are any high-risk customers to predict actions for
if high_risk_customers.empty:
    print("No high-risk customers found below the threshold.")
else:
    print(f"Number of high-risk customers: {len(high_risk_customers)}")

    required_features = [
	'Age',
	'Gender',          # Keep this for encoding
	'Loyalty Member',   # Keep this for encoding
	'Product Type',     # Keep this for encoding
	'Add-on Total',     # Include these additional features if they were used in training
	'Add-ons Purchased',
	'Total Price'
    ]

    # Extract features from high-risk customers
    customer_features = high_risk_customers[required_features]

    # Perform one-hot encoding for categorical features
    customer_features = pd.get_dummies(customer_features, drop_first=True)

    # Align columns in the same order as the training dataset
    # Retrieve columns used during training
    training_features = X_train.columns  # Get feature names from X_train

    common_features = list(set(training_features) & set(customer_features.columns))
    customer_features = customer_features[common_features]

    # Ensure all required columns are present, adding any missing ones with a default value of 0
    for col in training_features:
	if col not in customer_features.columns:
	    customer_features[col] = 0  # Add missing columns with a default value of 0

    customer_features = customer_features.reindex(columns=training_features, fill_value=0)

    # Align the columns to match the training set
    customer_features = customer_features[training_features]

    # Initialize a dictionary to hold predictions for each action
    predictions = []

    # Define the trained models for prediction
    models = {
	'discount_offer': models['discount_offer'],
	'loyalty_reward': models['loyalty_reward'],
	'product_promotion': models['product_promotion']
    }
      # Iterate through each high-risk customer and predict the best action
    for i in range(len(customer_features)):
	# Prepare a DataFrame for the current customer's features
	customer_data = pd.DataFrame([customer_features.iloc[i]])

	# Initialize a dictionary to store predicted probabilities for each action
	action_probabilities = {}

	# Predict probabilities for each action using the trained models


	for action in models.keys():
	    prob = models[action].predict_proba(customer_data)[:, 1]  # Get probability of class 1 (recommended action)
	    action_probabilities[action] = prob[0]  # Store the predicted probability for this action

	# Determine the action with the highest predicted probability
	best_action = max(action_probabilities, key=action_probabilities.get)

	# Store the results in the predictions list
	predictions.append({
	    'Customer ID': high_risk_customers.iloc[i]['Customer ID']
,  # Store original Customer ID
	    'Predicted Action': best_action,
	    'Action Probability': action_probabilities[best_action]  # Store the probability of the predicted action
	})

    # Convert the predictions to a DataFrame for easier interpretation
    predictions_df = pd.DataFrame(predictions)

    # Display the final predictions for review
    print(predictions_df)

# Step 10: Output next best actions
# For each high-risk customer:
#     - Output the recommended action(s) with the highest likelihood
#     - Store or display results for use in retention strategies (e.g., marketing, customer service)


# Find the maximum action probability across all customers
max_probability = predictions_df['Action Probability'].max()

# Filter for actions that match this maximum probability
high_confidence_actions = predictions_df[predictions_df['Action Probability'] == max_probability]

# Display the high-confidence actions
print("Recommended actions with the highest likelihood:")
print(high_confidence_actions)

# Save high-confidence actions to a CSV file for further use in retention strategies
high_confidence_actions.to_csv("high_confidence_actions.csv", index=False)
print("High-confidence recommendations saved to 'high_confidence_actions.csv'")

